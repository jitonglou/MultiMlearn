nfolds_outer = 2
nfolds_inner = 1 # more folds yield more training samples
eps = 1e-16
g_func = function(x){abs(x)} # weights on the outcome in SVM
max_size = 1 # size of the matched set
data=data_feature
idx=idx_data_feature
trts=levels(data_feature$treatment)
delta=max(dist_feature)
dist_mat=dist_feature
kernel="rbfdot"
kpar="automatic"
tuneGrid=ksvm.grid
propensity=pat_prop
foldid_outer=NULL
data(simdata200)
head(simdata200)
ls()
usethat::use_vignette("example")
install.packages("usethat")
devtools::use_vignette("example")
usethis::use_vignette("example")
aaa = data.frame(a1=1:2,a2=2:3)
aaa[cbind(1:2,c("a1","a2"))]
aaa[cbind(1:2,1:2]
aaa[cbind(1:2,1:2)]
bbb = as.factor(c("a2","a1"))
aaa[cbind(1:2,bbb)]
devtools::document()
devtools::document()
devtools::document()
?MultiMlearn
??MultiMlearn
?simulate.data
devtools::document()
?simulate.data
rm(aaa,bbb)
getMethod("pi.true")
getMethod(pi.true)
library(MultiMlearn)
?weighted.ksvm.2.cv # explanation of arguments
rseed = 0
set.seed(rseed)
# ?simulate.data # explanation of arguments
# ?pi.true # true propensity model used in the supplementary material
# ?mu.true # true main effects used in the supplementary material
# ?delta.true # true interaction effects used in the supplementary material
simdata = simulate.data(
N = 200, p = 20, K = 4, J = 4,
propensity_func = pi.true, main_func = mu.true, interaction_func = delta.true
)
table(treatment=simdata$treatment, group=simdata$group) # contingency table of observed treatment vs group
table(treatment=simdata$treatment, group=simdata$cluster) # contingency table of observed treatment vs group
group = 1
data_covariate = simdata %>%
filter(cluster == group) %>%
select(ID, cluster, reward, treatment, starts_with("feature"))
n_feature = ncol(data_covariate) - 4
table(data_covariate$treatment) # number of observed treatments in this group
metric = "RMSE"
tunegrid = expand.grid(.mtry=seq(1,n_feature/3, 1), .ntree=seq(500,1000,500))
control = trainControl(method="repeatedcv", number=10, repeats=3)
library(dplyr)
library(caret)
library(personalized)
metric = "RMSE"
tunegrid = expand.grid(.mtry=seq(1,n_feature/3, 1), .ntree=seq(500,1000,500))
control = trainControl(method="repeatedcv", number=10, repeats=3)
## train model
set.seed(rseed)
prognostic_fit = train(
reward~., data=data_covariate %>% select(-ID, -cluster, -treatment),
method=rfcv2("Regression"), metric=metric,
tuneGrid=tunegrid, trControl=control
)
print(prognostic_fit)
## estimators
sub_prog = predict(
prognostic_fit, newdata=data_covariate %>% select(-ID, -cluster, -treatment)
)
metric = "RMSE"
tunegrid = expand.grid(.mtry=seq(1,n_feature/3, 1), .ntree=seq(500,2000,500))
control = trainControl(method="repeatedcv", number=10, repeats=3)
## train model
set.seed(rseed)
prognostic_fit = train(
reward~., data=data_covariate %>% select(-ID, -cluster, -treatment),
method=rfcv2("Regression"), metric=metric,
tuneGrid=tunegrid, trControl=control
)
print(prognostic_fit)
## estimators
sub_prog = predict(
prognostic_fit, newdata=data_covariate %>% select(-ID, -cluster, -treatment)
)
metric = "Kappa"
tunegrid = expand.grid(.mtry=seq(1,sqrt(n_feature), 1), .ntree=seq(500,2000,500))
control = trainControl(method="repeatedcv", number=10, repeats=3)
## train model
set.seed(rseed)
propensity_fit = train(
treatment~., data=data_covariate %>% select(-ID, -cluster, -reward),
method=rfcv2("Classification"), metric=metric,
tuneGrid=tunegrid, trControl=control
)
print(propensity_fit)
## estimators
sub_prop = predict(
propensity_fit, newdata=data_covariate %>% select(-ID, -cluster, -reward), type = "prob"
)
metric = "Accuracy"
tunegrid = expand.grid(.mtry=seq(1,sqrt(n_feature), 1), .ntree=seq(500,2000,500))
control = trainControl(method="repeatedcv", number=10, repeats=3)
## train model (around 1 minute)
set.seed(rseed)
propensity_fit = train(
treatment~., data=data_covariate %>% select(-ID, -cluster, -reward),
method=rfcv2("Classification"), metric=metric,
tuneGrid=tunegrid, trControl=control
)
print(propensity_fit)
## estimators
sub_prop = predict(
propensity_fit, newdata=data_covariate %>% select(-ID, -cluster, -reward), type = "prob"
)
metric = "Kappa"
tunegrid = expand.grid(.mtry=seq(1,sqrt(n_feature), 1), .ntree=seq(500,2000,500))
control = trainControl(method="repeatedcv", number=10, repeats=3)
## train model (around 1 minute)
set.seed(rseed)
propensity_fit = train(
treatment~., data=data_covariate %>% select(-ID, -cluster, -reward),
method=rfcv2("Classification"), metric=metric,
tuneGrid=tunegrid, trControl=control
)
print(propensity_fit)
## estimators
sub_prop = predict(
propensity_fit, newdata=data_covariate %>% select(-ID, -cluster, -reward), type = "prob"
)
data_feature = data.frame(
data_covariate %>% mutate(reward_res = reward),
sub_prop %>% select(-levels(simdata$treatment)[1]), # remove propensity scores of the first treatment to avoid colinearity of propensity scores
prog = sub_prog
)
## compute the Euclidean distance between features of subjects
dist_feature = data_feature %>%
select(-ID, -cluster, -treatment, -reward, -reward_res) %>%
dist() %>%
as.matrix()
dim(dist_feature)
## Create an index data frame to select the corresponding row of the distance matrix
idx_data_feature = data.frame(ID=data_feature$ID, index=1:nrow(data_feature))
ksvm.grid = expand.grid(C = 2^(-8:8)) # a data frame of the tuning parameter
nfolds_outer = 3 # number of folds in the outer layer of the nested cross-validation
nfolds_inner = 3 # number of folds in the inner layer of the nested cross-validation
g_func = function(x){abs(x)} # weights on the outcome in support vector machines
max_size = 1 # maximum size of the matched set
set.seed(rseed)
# ?weighted.ksvm.2.cv # explanation of arguments
ITR_OVO = weighted.ksvm.2.cv(
data=data_feature, idx=idx_data_feature,
trts=levels(data_feature$treatment), max_size=max_size,
delta=max(dist_feature), dist_mat=dist_feature, g_func=g_func,
kernel="rbfdot", kpar="automatic",
nfolds_outer=nfolds_outer, nfolds_inner=nfolds_inner, tuneGrid=ksvm.grid, propensity=sub_prop,
foldid_outer=NULL
)
pi_vec = rep(NA, nrow(ITR_OVO$prediction))
for(i in 1:nrow(ITR_OVO$prediction)){
pi_vec[i] = pat_prop[i,ITR_OVO$prediction$treatment[i]]
}
df_evf = data.frame(ITR_OVO$prediction, pi=pi_vec, iter=rseed)
pi_vec = rep(NA, nrow(ITR_OVO$prediction))
for(i in 1:nrow(ITR_OVO$prediction)){
pi_vec[i] = sub_prop[i,ITR_OVO$prediction$treatment[i]]
}
df_evf = data.frame(ITR_OVO$prediction, pi=pi_vec, iter=rseed)
caret::confusionMatrix(as.factor(df_evf$vote), df_evf$treatment)
View(ITR_OVO)
devtools::document()
summary(ITR_OVO)
ITR=ITR_OVO
rm(ITR)
ITR=ITR_OVO
rm(ITR_OVO)
ITR$prediction$treatment %>% class
ITR$prediction$treatment
sub_prop[cbind(1:nrow(sub_prop), ITR$prediction$treatment)] %>% head
sub_prop %>% head
View(simdata)
View(ITR)
df_result = data.frame(
ITR$prediction,
pi = (simdata %>%
filter(cluster=group) %>%
select(starts_with("pi")))[cbind(1:nrow(sub_prop), ITR$prediction$treatment)], # estimated propensity scores of recommended treatments
treatment_opt=simdata %>%
filter(cluster=group) %>%
select(treatment_opt)
)
df_result = data.frame(
ITR$prediction,
pi = (simdata %>%
filter(cluster == group) %>%
select(starts_with("pi")))[cbind(1:nrow(sub_prop), ITR$prediction$treatment)], # estimated propensity scores of recommended treatments
treatment_opt=simdata %>%
filter(cluster == group) %>%
select(treatment_opt)
)
df_result %>%
group_by(treatment) %>%
summarize(evf=sum(reward/pi)/sum(1/pi),
miss_rate=sum(treatment==treatment_opt)/n()) %>%
as.data.frame()
df_result %>%
group_by(treatment) %>%
summarize(evf=sum(reward/pi)/sum(1/pi),
miss_rate=1-n()/nrow(df_result)) %>%
as.data.frame()
df_result = data.frame(
ITR$prediction,
pi = (simdata %>%
filter(cluster == group) %>%
select(starts_with("pi")))[cbind(1:nrow(sub_prop), ITR$prediction$treatment)], # estimated propensity scores of recommended treatments
treatment_opt=simdata %>%
filter(cluster == group) %>%
select(treatment_opt)
)
evf_val = function(reward, pi, x, y){
flag = x==y
return(sum((reward/pi)[flag])/sum((1/pi)[flag]))
}
df_result %>%
group_by(treatment) %>%
summarize(evf=sum(reward/pi)/sum(1/pi),
mis_rate=1-n()/nrow(df_result)) %>%
rbind(c("observed",
evf_val(df_result$reward, df_result$pi, df_result$treatment, df_result$treatment_opt),
1-sum(df_result$treatment==df_result$treatment_opt)/nrow(df_result))) %>%
rbind(c("recommended",
evf_val(df_result$reward, df_result$pi, df_result$vote, df_result$treatment_opt),
1-sum(df_result$treatment==df_result$treatment_opt)/nrow(df_result))) %>%
as.data.frame()
df_result %>%
group_by(treatment) %>%
summarize(evf=sum(reward/pi)/sum(1/pi),
mis_rate=1-n()/nrow(df_result)) %>%
rbind(c("observed",
evf_val(df_result$reward, df_result$pi, df_result$treatment, df_result$treatment_opt),
1-sum(df_result$treatment==df_result$treatment_opt)/nrow(df_result))) %>%
rbind(c("recommended",
evf_val(df_result$reward, df_result$pi, df_result$vote, df_result$treatment_opt),
1-sum(df_result$vote==df_result$treatment_opt)/nrow(df_result))) %>%
as.data.frame()
c("observed",
evf_val(df_result$reward, df_result$pi, df_result$treatment, df_result$treatment_opt),
1-sum(df_result$treatment==df_result$treatment_opt)/nrow(df_result))
c("recommended",
evf_val(df_result$reward, df_result$pi, df_result$vote, df_result$treatment_opt),
1-sum(df_result$vote==df_result$treatment_opt)/nrow(df_result))
df_result = data.frame(
ITR$prediction,
# pi = (simdata %>%
#   filter(cluster == group) %>%
#   select(starts_with("pi")))[cbind(1:nrow(sub_prop), ITR$prediction$treatment)], # estimated propensity scores of recommended treatments,
pi = sub_prop[cbind(1:nrow(sub_prop), ITR$prediction$treatment)],
treatment_opt = simdata %>%
filter(cluster == group) %>%
select(treatment_opt)
)
df_result %>%
group_by(treatment) %>%
summarize(evf=sum(reward/pi)/sum(1/pi),
mis_rate=1-n()/nrow(df_result)) %>%
as.data.frame() %>%
rbind(c("observed",
evf_val(df_result$reward, df_result$pi, df_result$treatment, df_result$treatment_opt),
1-sum(df_result$treatment==df_result$treatment_opt)/nrow(df_result))) %>%
rbind(c("recommended",
evf_val(df_result$reward, df_result$pi, df_result$vote, df_result$treatment_opt),
1-sum(df_result$vote==df_result$treatment_opt)/nrow(df_result)))
View(df_result)
df_result = data.frame(
ITR$prediction,
pi = (simdata %>%
filter(cluster == group) %>%
select(starts_with("pi")))[cbind(1:nrow(sub_prop), ITR$prediction$treatment)], # estimated propensity scores of recommended treatments,
# pi = sub_prop[cbind(1:nrow(sub_prop), ITR$prediction$treatment)],
treatment_opt = simdata %>%
filter(cluster == group) %>%
select(treatment_opt)
)
df_result = data.frame(
ITR$prediction,
pi = (simdata %>%
filter(cluster == group) %>%
select(starts_with("pi")))[cbind(1:nrow(sub_prop), ITR$prediction$vote)], # estimated propensity scores of recommended treatments,
# pi = sub_prop[cbind(1:nrow(sub_prop), ITR$prediction$vote)],
treatment_opt = simdata %>%
filter(cluster == group) %>%
select(treatment_opt)
)
df_result = data.frame(
ITR$prediction,
pi = (simdata %>%
filter(cluster == group) %>%
select(starts_with("pi")))[cbind(1:nrow(sub_prop), as.factor(ITR$prediction$vote))], # estimated propensity scores of recommended treatments,
treatment_opt = simdata %>%
filter(cluster == group) %>%
select(treatment_opt)
)
df_result %>%
group_by(treatment) %>%
summarize(evf=sum(reward/pi)/sum(1/pi),
mis_rate=1-n()/nrow(df_result)) %>%
as.data.frame() %>%
rbind(c("observed",
evf_val(df_result$reward, df_result$pi, df_result$treatment, df_result$treatment_opt),
1-sum(df_result$treatment==df_result$treatment_opt)/nrow(df_result))) %>%
rbind(c("recommended",
evf_val(df_result$reward, df_result$pi, df_result$vote, df_result$treatment_opt),
1-sum(df_result$vote==df_result$treatment_opt)/nrow(df_result)))
?within
with(df_result, sum(reward/pi)/sum(1/pi))
c("observed",
with(df_result, sum(reward/pi)/sum(1/pi)),
with(df_result, 1-sum(treatment==treatment_opt)/length(ID)))
c("recommended",
with(df_result, sum((reward/pi)[treatment==vote])/sum((1/pi)[treatment==vote])),
with(df_result, 1-sum(treatment==treatment_opt)/length(ID)))
df_result %>%
group_by(treatment) %>%
summarize(evf=sum(reward/pi)/sum(1/pi),
mis_rate=1-n()/nrow(df_result))
rm(df_evf)
evf.func = function(reward, pi, x, y){
flag = (x==y)
return(sum((reward/pi)[flag])/sum((1/pi)[flag]))
}
## data frame of results
summary_evf = ITR_prediction %>%
left_join(simdata %>% select(ID, pi_true, contains("opt")),
by = "ID") %>%
group_by(fold) %>%
summarize(
evf_obs = evf.func(reward, pi_true, treatment, treatment),
mis_obs = 1-sum(treatment_opt == treatment)/n(),
evf_rec = evf.func(reward, pi_true, treatment, vote),
mis_rec = 1-sum(treatment_opt == vote)/n(),
n=n() # sample size
) %>%
as.data.frame()
evf.func = function(reward, pi, x, y){
flag = (x==y)
return(sum((reward/pi)[flag])/sum((1/pi)[flag]))
}
## data frame of results
summary_evf = ITR$prediction %>%
left_join(simdata %>% select(ID, pi_true, contains("opt")),
by = "ID") %>%
group_by(fold) %>%
summarize(
evf_obs = evf.func(reward, pi_true, treatment, treatment),
mis_obs = 1-sum(treatment_opt == treatment)/n(),
evf_rec = evf.func(reward, pi_true, treatment, vote),
mis_rec = 1-sum(treatment_opt == vote)/n(),
n=n() # sample size
) %>%
as.data.frame()
summary(summary_evf)
devtools::document
devtools::document()
devtools::document()
devtools::document()
devtools::load_all()
library(MultiMlearn)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
?randomForest
devtools::document()
devtools::build()
devtools::install_github("jitonglou/MultiMlearn")
devtools::document()
devtools::document()
pwd
wd
pwd()
wd()
workdir()
wkdir()
getwd()
list.files("./R")
files = list.files("./R")
for (file in files){source(file)}
files = list.files("./R", full.names = TRUE)
for (file in files){source(file)}
View(simulate_data)
?devtools::install_github
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(MultiMlearn)
library(dplyr)
library(caret)
library(personalized)
rseed = 0
set.seed(rseed)
simdata = simulate_data(
N = 200, p = 20, K = 4, J = 4,
propensity_func = pi.true,
main_func = mu.true,
interaction_func = delta.true
)
# ?simulate_data # explanations of function arguments and the columns in the returned data frame
# ?pi.true # true propensity model used in the supplementary material
# ?mu.true # true main effects used in the supplementary material
# ?delta.true # true interaction effects used in the supplementary material
table(treatment=simdata$treatment, group=simdata$cluster) # contingency table of observed treatment vs group
group = 1
data_covariate = simdata %>%
filter(cluster == group) %>%
select(ID, cluster, reward, treatment, starts_with("feature"))
n_feature = ncol(data_covariate) - 4
metric = "RMSE"
tunegrid = expand.grid(.mtry=seq(1,n_feature/3, 1), .ntree=seq(500,2000,500))
control = trainControl(method="repeatedcv", number=10, repeats=3)
## train model (around 1 minute)
set.seed(rseed)
prognostic_fit = train(
reward~., data=data_covariate %>% select(-ID, -cluster, -treatment),
method=rfcv2("Regression"), metric=metric,
tuneGrid=tunegrid, trControl=control
)
print(prognostic_fit)
## estimators
sub_prog = predict(
prognostic_fit, newdata=data_covariate %>% select(-ID, -cluster, -treatment)
)
prognostic_fit
summary(prognostic_fit)
metric = "Kappa"
tunegrid = expand.grid(.mtry=seq(1,sqrt(n_feature), 1), .ntree=seq(500,2000,500))
control = trainControl(method="repeatedcv", number=10, repeats=3)
## train model (around 1 minute)
set.seed(rseed)
propensity_fit = train(
treatment~., data=data_covariate %>% select(-ID, -cluster, -reward),
method=rfcv2("Classification"), metric=metric,
tuneGrid=tunegrid, trControl=control
)
print(propensity_fit)
## estimators
sub_prop = predict(
propensity_fit, newdata=data_covariate %>% select(-ID, -cluster, -reward), type = "prob"
)
data_feature = data.frame(
data_covariate %>% mutate(reward_res = reward),
sub_prop %>% select(-levels(simdata$treatment)[1]), # remove propensity scores of the first treatment to avoid colinearity of propensity scores
prog = sub_prog
)
## compute the Euclidean distance between features of subjects
dist_feature = data_feature %>%
select(-ID, -cluster, -treatment, -reward, -reward_res) %>%
dist() %>%
as.matrix()
## Create an index data frame to select the corresponding row of the distance matrix
idx_data_feature = data.frame(ID=data_feature$ID, index=1:nrow(data_feature))
summary(dist_feature)
summary(c(dist_feature))
ksvm.grid = expand.grid(C = 2^(-8:8)) # a data frame of the tuning parameter
nfolds_outer = 3 # number of folds in the outer layer of the nested cross-validation
nfolds_inner = 3 # number of folds in the inner layer of the nested cross-validation
g_func = function(x){abs(x)} # weights on the outcome in support vector machines
max_size = 1 # maximum size of the matched set
## Fit M-learning model (around 2 minutes)
set.seed(rseed)
# ?mlearn.wsvm.cv # explanation of arguments
ITR = mlearn.wsvm.cv(
data=data_feature, idx=idx_data_feature,
trts=levels(data_feature$treatment), max_size=max_size,
delta=max(dist_feature), dist_mat=dist_feature, g_func=g_func,
kernel="rbfdot", kpar="automatic",
nfolds_outer=nfolds_outer, nfolds_inner=nfolds_inner, tuneGrid=ksvm.grid, propensity=sub_prop,
foldid_outer=NULL
)
summary(ITR)
head(ITR$prediction) # "vote" represents the recommended treatments for the subjects. "treatment" represents the observed treatments.
evf.func = function(reward, pi, x, y){
flag = (x==y)
return(sum((reward/pi)[flag])/sum((1/pi)[flag]))
}
## EVF and misclassification rate of observed and recommended treatments
summary_evf = ITR$prediction %>%
left_join(simdata %>% select(ID, pi_true, contains("opt")), # join the simdata to use true propensity score and optimal treatment information
by = "ID") %>%
group_by(fold) %>%
summarize(
evf_obs = evf.func(reward, pi_true, treatment, treatment),
mis_obs = 1-sum(treatment_opt == treatment)/n(),
evf_rec = evf.func(reward, pi_true, treatment, vote),
mis_rec = 1-sum(treatment_opt == vote)/n(),
n=n() # sample size in each fold
) %>%
as.data.frame
summary(summary_evf)
?source
devtools::load_all()
devtools::build()
